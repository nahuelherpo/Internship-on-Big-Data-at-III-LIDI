# Internship-on-Big-Data-at-III-LIDI
I have got a Spark based big data processing system up and running, got it up and running on an available cluster, done performance testing and bug detection.

## Requirements
 * Python 3.10
 * Poetry

## Getting started
 1. Install poetry (a python tool for version controling)
 2. Enter in the project folder
 3. Run the poetry commands to create (and in it) an isolated environment

    ```bash
    $ poetry install
    ```

    ```bash
    $ poetry shell
    ```
